{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Initiate Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoyochrist/Thesis/blob/master/Initiate_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFa5AFb7Xlfy",
        "colab_type": "code",
        "outputId": "373eeb97-17be-470b-e54e-b3174319cf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "from numpy.testing import assert_allclose\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "drive.mount(\"/content/gdrive/\")\n",
        "print(os.listdir(\"/content/gdrive/My Drive/Thesis/input\"))\n",
        "root_path='/content/gdrive/My Drive/Thesis/input/'\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n",
            "['master-raw.xlsx', 'master-raw.csv', 'wiki.id.vec', 'summaries', 'checkpoints', 'logs', 'test_x_res.csv', 'train_x_res.csv', 'valid_x.csv', 'train_y_res.csv', 'test_y_res.csv', 'valid_y.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN7ZOo1AXnQc",
        "colab_type": "code",
        "outputId": "f1fb1bdf-9838-4cf5-a283-06a5c6c5e765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, Input, LSTM, GRU, Conv1D, MaxPooling1D, Concatenate, Bidirectional, Flatten, Activation, RepeatVector, Permute, multiply\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
        "from keras.utils import np_utils\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.callbacks import Callback\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W5JeWYrXwGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initiate default values\n",
        "maxLen = 128          #maximum length of sentences\n",
        "\n",
        "master = pd.read_csv('/content/gdrive/My Drive/Thesis/input/master-raw.csv', sep=\",\")\n",
        "\n",
        "X = master.copy()\n",
        "y = pd.DataFrame()\n",
        "y['aspect'] = master['aspect']\n",
        "# y['rating'] = master['rating']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WnknQNJXxgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "tr = str.maketrans(string.punctuation, \" \"*32)\n",
        "def modify_phrase(ph, tr):\n",
        "    ph = ph.lower()\n",
        "    return ph.translate(tr).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM8rbbGvXyz6",
        "colab_type": "code",
        "outputId": "095187f1-de0e-42d2-8dc0-684b3a593190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modify_phrase(\"Hey there! I am here, using whatsapp!!...\", tr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hey there  i am here  using whatsapp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTLA5n73X08b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    vocab_size, dim = map(int, fin.readline().split())\n",
        "    word_to_vec_map = {}\n",
        "    words = set()\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        words.add(tokens[0])\n",
        "        word_to_vec_map[tokens[0]] = np.array(tokens[1:], dtype=np.float64)\n",
        "    i = 1\n",
        "    words_to_index = {}\n",
        "    index_to_words = {}\n",
        "    for w in sorted(words):\n",
        "        words_to_index[w] = i\n",
        "        index_to_words[i] = w\n",
        "        i = i + 1\n",
        "    return word_to_vec_map, words_to_index, index_to_words, vocab_size, dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWvMpxfnX3y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentences_to_indices(X, word_to_index, maxLen):\n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "    X_indices = np.zeros((m, maxLen))\n",
        "    \n",
        "    for i in range(m):\n",
        "        sentence_words = X[i].lower().strip().split()\n",
        "        j = 0\n",
        "        for w in sentence_words:\n",
        "            if w not in word_to_index:\n",
        "                w = \"person\"        #mostly names are not present in vocabulary\n",
        "            X_indices[i, j] = word_to_index[w]\n",
        "            if j < maxLen-1:\n",
        "              j = j + 1\n",
        "            else:\n",
        "              break\n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIFVKHnVYEdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load fastText word2vec model\n",
        "word_to_vec_map, word_to_index, index_to_words, vocab_size, dim= load_vectors('/content/gdrive/My Drive/Thesis/input/wiki.id.vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJktEeE0YFLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set X values into indices \n",
        "X_vec = sentences_to_indices(X.sentence, word_to_index, maxLen)\n",
        "X_pd_vec = pd.DataFrame(X_vec)\n",
        "\n",
        "#Set Y values into classes\n",
        "\n",
        "\n",
        "Y_encode = pd.get_dummies(y, columns=['aspect'])\n",
        "Y_encode['onehotencode'] = Y_encode[Y_encode.columns[:]].apply(\n",
        "    lambda x: ','.join(x.dropna().astype(int).astype(str)),\n",
        "    axis=1\n",
        ")\n",
        "Y = np.array(Y_encode['onehotencode'])\n",
        "\n",
        "# labelencoder = LabelEncoder() \n",
        "# # label = labelencoder.fit(Y.astype(str))\n",
        "# Y = labelencoder.fit_transform(np.reshape(Y, (Y.shape[0],1)))\n",
        "\n",
        "encode = OneHotEncoder(sparse=False)\n",
        "Y = encode.fit_transform(np.reshape(Y, (Y.shape[0], 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPbZWX-0QzPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yD7fPbZSAO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y_encode['onehotencode'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_jqFcgDSWCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwmrp3kYYaCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Over sampling using SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_pd_vec, Y)\n",
        "\n",
        "# ros = RandomOverSampler(random_state=42)\n",
        "# X_resampled, y_resampled = ros.fit_resample(X_pd_vec, y['aspect'])\n",
        "\n",
        "#Divide sampling into 75% training and 12.5% testing and 12.5% validation\n",
        "train_x, test_x, train_y, test_y = train_test_split(X_res, y_res, test_size = 0.4, stratify=y_res, random_state=42)\n",
        "test_x, val_x, test_y, val_y = train_test_split(test_x, test_y, test_size = 0.5, stratify=test_y, random_state=42)\n",
        "#test_x, valid_x, test_y, valid_y = train_test_split(test_x, test_y, test_size = 0.2, stratify=test_y, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha67NXX5zbsi",
        "colab_type": "code",
        "outputId": "80c5dd35-56fc-4895-9f57-d867ad23ad2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_x.shape, test_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((44979, 128), (44979, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hksxfjUi-eRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Over sampling using SMOTE\n",
        "# sm = SMOTE(random_state=42)\n",
        "# train_x_sm, train_y_sm = sm.fit_resample(train_x, Y_train)\n",
        "# test_x_sm, test_y_sm = sm.fit_resample(test_x, Y_test)\n",
        "\n",
        "#Translate all values into np.array\n",
        "# train_x_res = np.array(train_x)\n",
        "# test_x_res = np.array(test_x)\n",
        "# valid_x = np.array(val_x)\n",
        "\n",
        "# train_y_res = np.array(train_y)\n",
        "# test_y_res = np.array(test_y)\n",
        "# valid_y = np.array(val_y)\n",
        "\n",
        "train_x_res = pd.DataFrame(data=train_x)\n",
        "test_x_res = pd.DataFrame(data=test_x)\n",
        "valid_x = pd.DataFrame(data=val_x)\n",
        "\n",
        "train_y_res = pd.DataFrame(data=train_y)\n",
        "test_y_res = pd.DataFrame(data=test_y)\n",
        "valid_y = pd.DataFrame(data=val_y)\n",
        "\n",
        "# Saving the array\n",
        "train_x_res.to_csv(root_path+'train_x_res.csv', sep=',', encoding='utf-8')\n",
        "test_x_res.to_csv(root_path+'test_x_res.csv', sep=',', encoding='utf-8')\n",
        "valid_x.to_csv(root_path+'valid_x.csv', sep=',', encoding='utf-8')\n",
        "\n",
        "train_y_res.to_csv(root_path+'train_y_res.csv', sep=',', encoding='utf-8')\n",
        "test_y_res.to_csv(root_path+'test_y_res.csv', sep=',', encoding='utf-8')\n",
        "valid_y.to_csv(root_path+'valid_y.csv', sep=',', encoding='utf-8')\n",
        "\n",
        "# np.savetxt(root_path+\"train_x_res.csv\", train_x_res, delimiter=\",\")\n",
        "# np.savetxt(root_path+\"test_x_res.csv\", test_x_res, delimiter=\",\")\n",
        "# np.savetxt(root_path+\"valid_x.csv\", valid_x, delimiter=\",\")\n",
        "\n",
        "# np.savetxt(root_path+\"train_y_res.csv\", train_y_res, delimiter=\",\")\n",
        "# np.savetxt(root_path+\"test_y_res.csv\", test_y_res, delimiter=\",\")\n",
        "# np.savetxt(root_path+\"valid_y.csv\", valid_y, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}