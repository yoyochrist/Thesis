{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoyochrist/Thesis/blob/master/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFa5AFb7Xlfy",
        "colab_type": "code",
        "outputId": "07940844-ed29-49c1-9022-c5bea0ce64df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "from numpy.testing import assert_allclose\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "drive.mount(\"/content/gdrive/\")\n",
        "print(os.listdir(\"/content/gdrive/My Drive/Thesis/input\"))\n",
        "root_path='/content/gdrive/My Drive/Thesis/input/'\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n",
            "['master-raw.xlsx', 'master-raw.csv', 'wiki.id.vec', 'summaries', 'checkpoints', 'logs', 'train_x_res.csv', 'test_x_res.csv', 'valid_x.csv', 'train_y_res.csv', 'test_y_res.csv', 'valid_y.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN7ZOo1AXnQc",
        "colab_type": "code",
        "outputId": "2fe1c137-94fb-4fbf-9d2e-eb399f92b645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, Input, LSTM, GRU, Conv1D, MaxPooling1D, Concatenate, Bidirectional, Flatten, Activation, RepeatVector, Permute, multiply\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
        "from keras.utils import np_utils\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.callbacks import Callback\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WnknQNJXxgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxLen = 128          #maximum length of sentences\n",
        "\n",
        "import string\n",
        "tr = str.maketrans(string.punctuation, \" \"*32)\n",
        "def modify_phrase(ph, tr):\n",
        "    ph = ph.lower()\n",
        "    return ph.translate(tr).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM8rbbGvXyz6",
        "colab_type": "code",
        "outputId": "79003b43-471a-46a1-f608-e7c8da4dc313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modify_phrase(\"Hey there! I am here, using whatsapp!!...\", tr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hey there  i am here  using whatsapp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTLA5n73X08b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    vocab_size, dim = map(int, fin.readline().split())\n",
        "    word_to_vec_map = {}\n",
        "    words = set()\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        words.add(tokens[0])\n",
        "        word_to_vec_map[tokens[0]] = np.array(tokens[1:], dtype=np.float64)\n",
        "    i = 1\n",
        "    words_to_index = {}\n",
        "    index_to_words = {}\n",
        "    for w in sorted(words):\n",
        "        words_to_index[w] = i\n",
        "        index_to_words[i] = w\n",
        "        i = i + 1\n",
        "    return word_to_vec_map, words_to_index, index_to_words, vocab_size, dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWvMpxfnX3y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentences_to_indices(X, word_to_index, maxLen):\n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "    X_indices = np.zeros((m, maxLen))\n",
        "    \n",
        "    for i in range(m):\n",
        "        sentence_words = X[i].lower().strip().split()\n",
        "        j = 0\n",
        "        for w in sentence_words:\n",
        "            if w not in word_to_index:\n",
        "                w = \"person\"        #mostly names are not present in vocabulary\n",
        "            X_indices[i, j] = word_to_index[w]\n",
        "            if j < maxLen-1:\n",
        "              j = j + 1\n",
        "            else:\n",
        "              break\n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIFVKHnVYEdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load fastText word2vec model\n",
        "word_to_vec_map, word_to_index, index_to_words, vocab_size, dim= load_vectors('/content/gdrive/My Drive/Thesis/input/wiki.id.vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5ESdaXCYzAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    vocab_len = len(word_to_index) + 1\n",
        "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
        "    \n",
        "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "    \n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "\n",
        "    embedding_layer = Embedding(input_dim = vocab_len, output_dim = emb_dim, trainable = False) \n",
        "\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    \n",
        "    return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymvvxac8Y0T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def restaurant_review_analysis(input_shape, word_to_vec_map, word_to_index, method, attention):\n",
        "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "    \n",
        "    embeddings = embedding_layer(sentence_indices)\n",
        "    \n",
        "    if attention == True:\n",
        "      activations = LSTM(units=128, dropout=0.4, return_sequences=True)(embeddings)     \n",
        "      attention = Dense(1, activation='tanh')(activations)\n",
        "      attention = Flatten()(attention)\n",
        "      attention = Activation('relu')(attention)\n",
        "      attention = RepeatVector(128)(attention)\n",
        "      attention = Permute([2, 1])(attention)\n",
        "\n",
        "      sent_representation = multiply([activations, attention])\n",
        "    else:\n",
        "      sent_representation = embeddings\n",
        "      \n",
        "    if method == 'CNN':\n",
        "      model = Sequential()\n",
        "      X1 = Conv1D(128, 64)(sent_representation)\n",
        "      X2 = Conv1D(128, 64)(sent_representation)\n",
        "      X3 = Conv1D(128, 64)(sent_representation)\n",
        "      X1 = MaxPooling1D(pool_size=32)(X1)\n",
        "      X2 = MaxPooling1D(pool_size=32)(X2)\n",
        "      X3 = MaxPooling1D(pool_size=32)(X3)\n",
        "      X = Concatenate(axis=1)([X1, X2, X3])\n",
        "      X = Flatten()(X)\n",
        "      X = Dense(units=4, activation='relu')(X)\n",
        "    elif method == 'LSTM':\n",
        "      #X = LSTM(units=128, dropout=0.4)(sent_representation)\n",
        "      X = LSTM(units=128, dropout=0.3, return_sequences=True)(sent_representation)\n",
        "      X = Flatten()(X)\n",
        "      X = Dense(units=4, activation='relu')(X)\n",
        "    else:\n",
        "      X = Bidirectional(LSTM(units=128, dropout=0.3, return_sequences=True))(sent_representation)\n",
        "      X = Flatten()(X)\n",
        "      X = Dense(units=4, activation='relu')(X)\n",
        "    \n",
        "    model = Model(inputs=sentence_indices, outputs=X)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odwGZmmfY1_5",
        "colab_type": "code",
        "outputId": "4c2737f6-6b03-4bc3-83a1-748d4fb713b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "# model_cnn = restaurant_review_analysis((maxLen,), word_to_vec_map, word_to_index, \"CNN\", False)\n",
        "# model_lstm = restaurant_review_analysis((maxLen,), word_to_vec_map, word_to_index, \"LSTM\", False)\n",
        "# model_blstm = restaurant_review_analysis((maxLen,), word_to_vec_map, word_to_index, \"BiLSTM\", False)\n",
        "# model_cnn_att = restaurant_review_analysis((maxLen,), word_to_vec_map, word_to_index, \"CNN\", True)\n",
        "# model_lstm_att = restaurant_review_analysis((maxLen,), word_to_vec_map, word_to_index, \"LSTM\", True)\n",
        "model_blstm_att = restaurant_review_analysis((maxLen,), word_to_vec_map, word_to_index, \"BiLSTM\", True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 03:03:40.527044 140037968222080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0731 03:03:40.566877 140037968222080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 03:03:41.663922 140037968222080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0731 03:03:41.680233 140037968222080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0731 03:03:41.681321 140037968222080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0731 03:03:45.280679 140037968222080 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRuBTFqiY4pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TimeHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zviivXJMY6F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "  # Count positive samples.\n",
        "  c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "\n",
        "  # If there are no true samples, fix the F1 score at 0.\n",
        "#   if c3 == 0:\n",
        "#     return 0\n",
        "\n",
        "  # How many selected items are relevant?\n",
        "  precision = c1 / c2\n",
        "\n",
        "  # How many relevant items are selected?\n",
        "  recall = c1 / c3\n",
        "\n",
        "  # Calculate f1_score\n",
        "  f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "  return f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhOOUIiSZFOR",
        "colab_type": "code",
        "outputId": "c9409883-7b09-4c6b-f8b5-0704d75b7bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# model_cnn.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\",f1_score])\n",
        "# model_cnn.compile(optimizer = Adam(lr=0.0005), loss = \"categorical_crossentropy\", metrics = [\"accuracy\",f1_score])\n",
        "# model_lstm.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\",f1_score])\n",
        "# model_blstm.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\",f1_score])\n",
        "# model_cnn_att.compile(optimizer = Adam(lr=0.0005), loss = \"categorical_crossentropy\", metrics = [\"accuracy\",f1_score])\n",
        "# model_lstm_att.compile(optimizer = Adam(lr=0.0005), loss = \"categorical_crossentropy\", metrics = [\"accuracy\",f1_score])\n",
        "model_blstm_att.compile(optimizer = Adam(lr=0.0005), loss = \"categorical_crossentropy\", metrics = [\"accuracy\",f1_score])\n",
        "\n",
        "earlystop = EarlyStopping(monitor='acc', min_delta=0.000001, patience=10, \\\n",
        "                          mode='auto')\n",
        "time_callback = TimeHistory()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 03:03:50.892448 140037968222080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d3A_g9hZJUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from contextlib import redirect_stdout\n",
        "\n",
        "# with open(root_path+'summaries/model_cnn_summary.txt', 'w+') as f:\n",
        "#   with redirect_stdout(f):\n",
        "#     model_cnn.summary()\n",
        "\n",
        "# with open(root_path+'summaries/model_lstm_summary.txt', 'w+') as f:\n",
        "#   with redirect_stdout(f):\n",
        "#     model_lstm.summary()\n",
        "    \n",
        "# with open(root_path+'summaries/model_blstm_summary.txt', 'w+') as f:\n",
        "#   with redirect_stdout(f):\n",
        "#     model_blstm.summary()\n",
        "\n",
        "# with open(root_path+'summaries/model_cnn_att_summary.txt', 'w+') as f:\n",
        "#   with redirect_stdout(f):\n",
        "#     model_cnn_att.summary()\n",
        "\n",
        "# with open(root_path+'summaries/model_lstm_att_summary.txt', 'w+') as f:\n",
        "#   with redirect_stdout(f):\n",
        "#     model_lstm_att.summary()\n",
        "    \n",
        "with open(root_path+'summaries/model_blstm_att_summary.txt', 'w+') as f:\n",
        "  with redirect_stdout(f):\n",
        "    model_blstm_att.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NuOSVUE00cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = pd.read_csv(root_path+\"train_x_res.csv\")\n",
        "x_test = pd.read_csv(root_path+\"test_x_res.csv\")\n",
        "x_valid = pd.read_csv(root_path+\"valid_x.csv\")\n",
        "\n",
        "y_train = pd.read_csv(root_path+\"train_y_res.csv\")\n",
        "y_test = pd.read_csv(root_path+\"test_y_res.csv\")\n",
        "y_valid = pd.read_csv(root_path+\"valid_y.csv\")\n",
        "\n",
        "train_x = np.array(x_train)\n",
        "test_x = np.array(x_test)\n",
        "valid_x = np.array(x_valid)\n",
        "\n",
        "train_y = np.array(y_train)\n",
        "test_y = np.array(y_test)\n",
        "valid_y = np.array(y_valid)\n",
        "\n",
        "# x_train = np.genfromtxt(root_path+\"train_x_res.csv\", delimiter=\",\")\n",
        "# x_test = np.genfromtxt(root_path+\"test_x_res.csv\", delimiter=\",\")\n",
        "# x_valid = np.genfromtxt(root_path+\"valid_x.csv\", delimiter=\",\")\n",
        "\n",
        "# y_train = np.genfromtxt(root_path+\"train_y_res.csv\", delimiter=\",\")\n",
        "# y_test = np.genfromtxt(root_path+\"test_y_res.csv\", delimiter=\",\")\n",
        "# y_valid = np.genfromtxt(root_path+\"valid_x.csv\", delimiter=\",\")\n",
        "\n",
        "train_x = train_x[:,1:]\n",
        "test_x = test_x[:,1:]\n",
        "valid_x = valid_x[:,1:]\n",
        "\n",
        "train_y = train_y[:,1:]\n",
        "test_y = test_y[:,1:]\n",
        "valid_y = valid_y[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSroBRsa_7bq",
        "colab_type": "code",
        "outputId": "4c58c81f-a838-4301-d265-1f3c6488308f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134937, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD7pvwo3Op0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(root_path+'checkpoints/model_blstm-3.hdf5', monitor='acc', verbose=1, \\\n",
        "                             save_best_only=True,\\\n",
        "                             mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0uIFW3oZNe2",
        "colab_type": "code",
        "outputId": "3c563bba-0d86-4160-cc2f-693fbc32d36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "csv_logger = CSVLogger(root_path+'logs/training_blstm.log')\n",
        "# callbacks_list = [earlystop, csv_logger,checkpoint, time_callback]\n",
        "callbacks_list = [csv_logger,checkpoint, time_callback]\n",
        "# track_cnn = model_blstm.fit(train_x, train_y, batch_size=128, epochs=70, callbacks=callbacks_list)\n",
        "track_blstm = model_blstm_att.fit(train_x, train_y, batch_size=128, epochs=30, validation_data=(valid_x, valid_y), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 03:08:02.147935 140037968222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 134937 samples, validate on 44980 samples\n",
            "Epoch 1/30\n",
            "134937/134937 [==============================] - 682s 5ms/step - loss: 3.8667 - acc: 0.4118 - f1_score: nan - val_loss: 0.7115 - val_acc: 0.6796 - val_f1_score: 0.6006\n",
            "\n",
            "Epoch 00001: acc improved from inf to 0.41179, saving model to /content/gdrive/My Drive/Thesis/input/checkpoints/model_blstm-3.hdf5\n",
            "Epoch 2/30\n",
            " 70912/134937 [==============>...............] - ETA: 4:47 - loss: 0.7372 - acc: 0.6857 - f1_score: 0.6253"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jx-MbhHFjcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(root_path+'logs/history-model-cnn-time.json', 'w') as f:\n",
        "#     json.dump(time_callback.times, f)\n",
        "\n",
        "with open(root_path+'logs/history-model-blstm-att-time.json', 'w') as f:\n",
        "    json.dump(time_callback.times, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpzENK84slsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzaue0XM1CfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_logger = CSVLogger(root_path+'logs/training_blstm-att-2.log')\n",
        "# callbacks_list = [earlystop, csv_logger,checkpoint, time_callback]\n",
        "callbacks_list = [csv_logger,checkpoint, time_callback]\n",
        "# load the model\n",
        "new_model = load_model(root_path+'checkpoints/model_blstm_att-3.hdf5', custom_objects={'f1_score':f1_score})\n",
        "np.allclose(model_blstm_att.predict(train_x),new_model.predict(train_x),1e-5)\n",
        "# fit the model\n",
        "track_blstm_2 = new_model.fit(train_x, train_y, epochs=30, batch_size=128, validation_data=(valid_x, valid_y), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zc1iqEc8uUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQjSP-c62rPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTG-WPQnXZEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_blstm.predict(train_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYABw-XSXcuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.predict(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWcAJ_bdc6Gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert_allclose(model_blstm.predict(x_train),new_model.predict(x_train),1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Okdb0xnZQRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(root_path+'logs/history-model-cnn-time.json', 'w') as f:\n",
        "#     json.dump(time_callback.times, f)\n",
        "\n",
        "with open(root_path+'logs/history-model-blstm-att-time-2.json', 'w') as f:\n",
        "    json.dump(time_callback.times, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8xLYDRZ1C2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_logger = CSVLogger(root_path+'logs/training_blstm-att-3.log')\n",
        "# callbacks_list = [earlystop, csv_logger,checkpoint, time_callback]\n",
        "callbacks_list = [csv_logger,checkpoint, time_callback]\n",
        "# load the model\n",
        "new_model_2 = load_model(root_path+'checkpoints/model_blstm_att-3.hdf5', custom_objects={'f1_score':f1_score})\n",
        "np.allclose(model_blstm_att.predict(train_x),new_model_2.predict(train_x),1e-5)\n",
        "\n",
        "# fit the model\n",
        "track_blstm_3 = new_model_2.fit(train_x, train_y, batch_size=128, epochs=30, validation_data=(valid_x, valid_y), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8MqT4573YG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(root_path+'logs/history-model-cnn-time.json', 'w') as f:\n",
        "#     json.dump(time_callback.times, f)\n",
        "\n",
        "with open(root_path+'logs/history-model-blstm-att-time-3.json', 'w') as f:\n",
        "    json.dump(time_callback.times, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_f6K_1Z1HRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_logger = CSVLogger(root_path+'logs/training_blstm-att-4.log')\n",
        "# callbacks_list = [earlystop, csv_logger,checkpoint, time_callback]\n",
        "callbacks_list = [csv_logger,checkpoint, time_callback]\n",
        "# load the model\n",
        "new_model_3 = load_model(root_path+'checkpoints/model_blstm_att-3.hdf5', custom_objects={'f1_score':f1_score})\n",
        "np.allclose(model_blstm_att.predict(train_x),\n",
        "                           new_model_3.predict(train_x),\n",
        "                           1e-5)\n",
        "\n",
        "# fit the model\n",
        "track_blstm_4 = new_model_3.fit(train_x, train_y, batch_size=128, epochs=10, validation_data=(valid_x, valid_y), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUaVmmHQ3Y7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(root_path+'logs/history-model-cnn-time.json', 'w') as f:\n",
        "#     json.dump(time_callback.times, f)\n",
        "\n",
        "with open(root_path+'logs/history-model-blstm-att-time-4.json', 'w') as f:\n",
        "    json.dump(time_callback.times, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNZMdDB6MO25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint = ModelCheckpoint(root_path+'checkpoints/model_blstm-3.hdf5', monitor='acc', verbose=2, \\\n",
        "#                              save_best_only=True, save_weights_only=False,\\\n",
        "#                              mode='auto', period=1)\n",
        "# csv_logger = CSVLogger(root_path+'logs/training_cnn.log')\n",
        "# # callbacks_list = [earlystop, csv_logger,checkpoint, time_callback]\n",
        "# callbacks_list = [csv_logger,checkpoint, time_callback]\n",
        "# track_cnn = model_blstm.fit(train_x, train_y, batch_size=128, epochs=70, callbacks=callbacks_list)\n",
        "# # track_cnn = model_cnn.fit(train_x, train_y, batch_size=128, epochs=200, validation_data=(valid_x, valid_y), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXvC3HWqJT5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint = ModelCheckpoint(root_path+'checkpoints/model_lstm-3.hdf5', monitor='acc', verbose=2, \\\n",
        "#                              save_best_only=True, save_weights_only=False,\\\n",
        "#                              mode='auto', period=1)\n",
        "# csv_logger = CSVLogger(root_path+'logs/training_lstm.log')\n",
        "# # callbacks_list = [earlystop, csv_logger,checkpoint, time_callback]\n",
        "# callbacks_list = [csv_logger,checkpoint, time_callback]\n",
        "# track_lstm = model_lstm.fit(train_x, train_y, batch_size=128, epochs=200, validation_data=(valid_x, valid_y), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwvM8fBBZSRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(track_blstm.history['acc'])\n",
        "plt.title('BiLSTM Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0)\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "plt.savefig(root_path+'graphs/blstm_att_acc_fig-2.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKz0BexNZUdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(track_cnn.history['loss'])\n",
        "# plt.title('CNN Model Loss')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train'], loc='upper left')\n",
        "# plt.savefig(root_path+'graphs/cnn_loss_fig-2.png')\n",
        "# plt.show()\n",
        "\n",
        "plt.plot(track_blstm.history['loss'])\n",
        "plt.title('BiLSTM Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "plt.savefig(root_path+'graphs/blstm_att_loss_fig-2.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNKVCxCXZWbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# score = model_cnn.evaluate(test_x, test_y, verbose=1)\n",
        "# print('CNN Test Loss:', score[0])\n",
        "# print('CNN Test Accuracy:', score[1])\n",
        "\n",
        "score = model_blstm_att.evaluate(test_x, test_y, verbose=1)\n",
        "print('BiLSTM Attenntion Test Loss:', score[0])\n",
        "print('BiLSTM Attenntion Test Accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}